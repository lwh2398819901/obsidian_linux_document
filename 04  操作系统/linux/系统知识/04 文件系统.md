ps： 这一章节不满意 抽时间重写

```toc
```
## 文件系统

为什么需要文件系统呢？
![[文件系统特性.png]]

### 虚拟文件系统
![[VFS.png]]

- vfs针对文件系统定义了一套通用接口，所有与文件交互的程序都按照这一接口操作
- 每种文件系统都会实现vfs接口
- 非unxi的文件系统　不支持所有vfs操作(例如：微软的vfat不支持symlink 符号链接)，遇到这种情况，底层文件系统会将错误代码传入vfs层，表明不支持该操作。vfs层将错误传递给应用程序。
- vfs接口的操作与涉及文件系统和目录的所有常规系统调用相对应，这些系统调用有open(),read(),write(),lseek(),close(),truncate(),stat(),mount(),umount(),mmap(),mkdir(),link(),unlimk(),symlink(),rename()。
- 在这里补充一句 c或者c++语言的io操作如fopen等 内部其实是调用操作系统的系统调用函数。


### 日志文件系统(ext3/ext4/xfs)
优点：
缺点：

日志文件系统的几种策略：
- 日志只写动作
- 日志同时写入动作和数据

#### xfs

查看前可能需要先卸载挂载点

![[xfs_info示例.png]]


<iframe 
 height=500
 width=1000  
src="https://blog.csdn.net/weixin_31869917/article/details/116732619"　
>
</iframe>



### 非日志文件系统


#### ext2文件系统


Ext2文件系统专注于高性能，以及下面列出和由文件系统作者在[CTT]中规定的目标。
- 支持可变块长，使得文件系统能够处理预期的应用（许多大文件或许多小文件）。
- 快速符号链接，如果链接目标的路径足够短，则将其存储在inode自身中（不是存储在数据区中）。
- 将扩展能力集成到设计中，使得从旧版本迁移到新版本时，无需重新格式化和重新加载硬盘。
- 在存储介质上操作数据时采用了一种精巧复杂的策略，使得系统崩溃可能造成的影响最小。
- 文件系统通常可以恢复到一种状态，在该状态下辅助工具fsck至少能够修复它，使得文件系统能够再次使用。这并不排除数据丢失的可能性。
- 使用特殊的属性（经典的UNIX文件系统不具备该特性）将文件标记为不可改变的。例如，这可以防止对重要配置文件的无意修改，即使超级用户也不行。[[02 权限控制#chattr lsattr|可参考权限控制 =>chattr lsattr]]

##### 物理结构
> 必须建立各种结构（在内核中定义为C语言数据类型），来存放文件系统的数据，包括文件内容、目录层次结构的表示、相关的管理数据（如访问权限或与用户和组的关联），以及用于管理文件系统内部信息的元数据。这些对从块设备读取数据进行分析而言，都是必要的。这些结构的持久副本显然需要存储在硬盘上，这样数据在两次会话之间不会丢失。下一次启动重新激活内核时，数据仍然是可用的。
> 因为硬盘和物理内存的需求不同，同一数据结构通常会有两个版本。一个用于在磁盘上的持久存储，另一个用于在内存中的处理。

Ext2文件系统是一种基于块的文件系统，它将硬盘划分为若干块，每个块的长度都相同，按块管理元数据和文件内容。这意味着底层存储介质的结构影响到了文件系统的结构，这很自然也会影响到所用的算法和数据结构的设计。
在将硬盘划分为固定长度的块时，特别重要的一个方面是文件占用的存储空间只能是块长度的整数倍。
下面来讲一下这个影响：
我们假定块长为5个单位。我们需要存储3个文件，长度分别如下
A文件：11个单位 
B文件：4个单位
C文件：2个单位。
![[基于块的文件系统中文件数据分布示例.png]]

很显然，上半部给出的方法在划分现存存储空间时效率更高，其中将各个文件的内容尽可能紧凑地分布到可用的块上。
但实际上没有使用该方法，因为它有一个==严重==的缺点由于同一块可能分配给不同的文件，因此需要一部分数据来管理各个块内部的文件边界，这部分数据的量是如此之大，以至于迅即抵消了该方法节省文件存储空间的好处（与图中下半部相比）。
最终，每个文件占用的存储空间的长度不仅仅包括其数据的长度，而且需要将数据长度向上舍入到块长的整数倍


```ps： “没有使用”严格来说是不准确的，这种方案的一种弱化形式（在某种程度上）允许使用一个块来保存几个小文件，此方案正在开发中，有可能成为Ext2/3文件系统未来版本的标准特性。尽管用于支持此类“碎片”的基本的基础设施已经包含在代码中，但特性本身尚未实现```

下面给出了一个块组（block group）的内容，块组是Ext2文件系统的核心要素。

![[ext2块组.png]]

- 超级块 superblock:记录文件系统的整体信息，包括inode/block总量，使用量，剩余量，以及文件系统格式以及相关信息。
- 组描述符：包含的信息反映了文件系统中各个块组的状态，例如，块组中空闲块和inode的数目。每个块组都包含了文件系统中所有块组的组描述符信息
- 数据块位图和inode位图用于保存长的比特位串。这些结构中的每个比特位都对应于一个数据块inode，用于表示对应的数据块或inode是空闲的，还是被使用中
- inode表 inode:记录文件属性，一个文件占用一个inode,同时记录此文件数据所在的block号码
- 数据块 block:实际记录文件的内容。



块组是该文件系统的基本成分，容纳了文件系统的其他结构。每个文件系统都由大量块组组成，在硬盘上相继排布
![[硬盘的启动扇区和块组.png]]

_ps:这里有一点不知道大家注意到没有，每一个块组上都有超级块 记录的内容都是整个文件系统的信息，块组描述符同样记录这个文件系统的块组信息，这其实是一种冗余。_
但是为什么这样做呢？有以下两个原因：
1.如果系统崩溃破坏了超级块，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的（难度极高，大多数用户可能一点也恢复不了）。
2.通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。

而且实际上，数据并非在每个块组中都复制，内核也只用超级块的第一个副本工作，通常这就足够了。
在进行文件系统检查时，会将第一个超级块的数据传播到剩余的超级块，供紧急情况下读取。因为该
方法也会消耗大量的存储空间，Ext2的后续版本采用了稀疏超级块（sparse superblock）技术。该做法中，超级块不再存储到文件系统的每个块组中，而是只写入到块组0、块组1和其他ID可以表示为3、5、7的幂的块组中。超级块的数据缓存在内存中，使得内核不必重复地从硬盘读取该数据（内存当然比硬盘快得多）。
上文中，为块组的冗余信息辩解的第二个原因现在也不成立了，现在已经不必在各个超级块之间进行
磁头寻道了。
尽管在设计Ext2文件系统时假定上述两个问题对文件系统的性能和安全有很大影响，但后来发现
情况不是这样。因此做出了上述修改。




#### inode结构

![[ext2 inode简要说明.png]]



|块长度| 最大文件长度|
|-------|--------------|
|1 024| 16 GiB| 
|2 048 |256 GiB| 
|4 096 |2 TiB|

**表 Ext2文件系统中的块长度和文件长度**



#### 预分配
为提高块分配的性能，Ext2文件系统采用了一种称之为预分配的机制。每当对一个文件请求许多新块时，不会只分配所需要的块数。能够用于连续分配的块，会另外被秘密标记出来，供后续使用。
内核确保各个保留的区域是不重叠的。这在进行新的分配时可以节省时间以及防止碎片，特别是在有多个文件并发增长时。
应该强调指出：预分配并不会降低可用空间的利用率。由一个inode预分配的空间，如果有需要，那么随时可能被另一个inode覆盖。但内核会尽力避免这种做法。我们可以将预分配想象为最后分配块之前的一个附加层，用于判断如何充分利用可用空间。预分配只是建议，而分配才是最终决定

![[Ext2预分配.png]]


#### 创建文件系统
文件系统并非由内核自身创建，而是由mke2fs用户空间工具创建的。
mke2fs不仅将分区的空间划分到管理信息和有用数据两个方面，还在存储介质上创建一个简单的目录结构，使得该文件系统能够装载。
这里的管理信息指的是哪些？在装载一个新格式化的Ext2分区时，其中已经包含了一个标准的子目录，名为lost+found，用于容纳存储介质上的坏块（幸亏现在硬盘的质量较好，这个目录几乎总是空的）。






## 虚拟文件系统
>通常，一个完整的Linux系统由数千到数百万个文件组成，文件中存储了程序、数据和各种信息。层次化的目录结构用于对文件进行编目和分组。其中采用了各种方法来永久存储所需的结构和数据。
>
>每种操作系统都至少有一种“标准文件系统”，提供了或好或差的一些功能，用以可靠而高效地执行所需的任务。
>
>为支持各种本机文件系统，且在同时允许访问其他操作系统的文件，Linux内核在用户进程（或C标准库）和文件系统实现之间引入了一个抽象层。该抽象层称之为虚拟文件系统（Virtual File System），简称VFS。

![[vfs抽象.png]]

###  文件系统类型
- 基于磁盘的文件系统（disk-based filesystem）
__是在非易失介质上存储文件的经典方法，用以在多次会话之间保持文件的内容。__
`必须解决以下问题：`如何将文件内容和结构信息存储在目录层次结构上?
在这里我们对与底层块设备通信的方法不感兴趣，内核中对应的驱动程序对此提供了统一的接口。从文件系统的角度来看，底层设备无非是存储块组成的一个列表，文件系统相当于对该列表实施一个适当的组织方案。
- 虚拟文件系统(virtual filesystem) 
也就是本章节将要介绍的内容，在内核中生成，是一种使用户应用程序与用户通信的方法。
proc文件系统是这一类的最佳示例。它不需要在任何种类的硬件设备上分配存储空间。相反，内核建立了一个层次化的文件结构，其中的项包含了与系统特定部分相关的信息。
- 网络文件系统(network filesystem)
`是基于磁盘的文件系统和虚拟文件系统之间的折中。`
这种文件系统允许访问另一台计算机上的数据，该计算机通过网络连接到本地计算机。在这种情况下，数据实际上存储在一个不同系统的硬件设备上。
这意味着内核无需关注文件存取、数据组织和硬件通信的细节，这些由远程计算机的内核处理。对此类文件系统中文件的操作都通过网络连接进行。在进程向文件写数据时，数据使用特定的协议（由具体的网络文件系统决定）发送到远程计算机。接下来远程计算机负责存储传输的数据并通知发送者数据已经到达。
尽管如此，即使在内核处理网络文件系统时，仍然需要文件长度、文件在目录层次中的位置以及文件的其他重要信息。它必须也提供函数，使得用户进程能够执行通常的文件相关操作，如打开、读、删除等。__由于VFS抽象层的存在，用户空间进程不会看到本地文件系统与网络文件系统之间的区别。__
比较有代表例子的是nfs服务。

### 通用文件模型
VFS不仅为文件系统提供了方法和抽象，还支持文件系统中对象（或文件）的统一视图。由于各个文件系统的底层实现不同，其语义经常有许多小而微妙的差异。并非所有文件系统都支持同样的功能，而有些操作（对“普通”文件是不可缺少的）对某些对象完全没有意义，例如集成到VFS中的`命名管道`。并非每一种文件系统都支持VFS中的所有抽象。`设备文件无法存储在源自其他系统的文件系统中（如FAT），后者的设计没有考虑到此类对象。`
![[vfat下无法创建命名管道.png]]
定义一个最小的通用模型，来支持内核中所有文件系统都实现的那些功能，这是不实际的。__因为这样会损失许多本质性的功能特性，或者导致这些特性只能通过特定文件系统的路径访问。__ VFS的方案完全相反：提供一种结构模型，包含了一个强大文件系统所应具备的所有组件。但该模型只存在于虚拟中，必须使用各种对象和函数指针与每种文件系统适配。所有文件系统的实现都必须提供与VFS定义的结构配合的例程，以弥合两种视图之间的差异。
>当然，虚拟文件系统的结构并非是幻想出来的东西，而是基于描述经典文件系统所使用的结构。VFS抽象层的组织显然也与Ext2文件系统类似。这对于基于完全不同概念的文件系统来说，会更加困难（例如，Reiser或XFS文件系统），但处理Ext2文件系统时会提高性能，因为在Ext2和VFS结构之间转换，几乎不会损失时间。

在处理文件时，内核空间和用户空间使用的主要对象是不同的。对用户程序来说，一个文件由一个文件描述符标识。该描述符是一个整数，在所有有关文件的操作中用作标识文件的参数。文件描述符是在打开文件时由内核分配，只在一个进程内部有效。两个不同进程可以使用同样的文件描述符，但二者并不指向同一个文件。基于同一个描述符来共享文件是不可能的。
内核处理文件的关键是inode。每个文件（和目录）都有且只有一个对应的indoe，其中包含元数据（如访问权限、上次修改的日期，等等）和指向文件数据的指针。但inode并不包含一个重要的信息项，即文件名，这看起来似乎有些古怪。通常，假定文件名称是其主要特征之一，因此应该被归入用于管理文件的对象（inode）中。之所以没有这样做有原因的。


#### inode 
在磁盘管理章节中，我们知道了对于ext2文件系统，每一个文件都有一个唯一的inode，包括目录同样也被看作文件，所以也有一个inode。






<br/>

推荐阅读的博客 :https://www.cnblogs.com/leesf456/p/5626339.html